\documentclass[11pt]{article}
\usepackage{xcolor}
\begin{document}



\textbf{Response to Review for Manuscript Number: SIM-22-0426}


Title: "Confidence Intervals for Prevalence Estimates from Complex Surveys with Imperfect Assays"

We are grateful to the editor and reviewers for their thoughtful comments and the opportunity to improve and resubmit our manuscript.
Our response to individual comments from each reviewer follow.

\textbf{Reviewer: 1}
(There are no comments.)

\textbf{Reviewer 2}

\begin{itemize}
    \item \textbf{This paper has many strengths and yet could benefit from a revision that clarifies the main contribution(s) of the work. The new method is mathematically clever and appears to have the nice property of guaranteeing nominal CI coverage (though it is unclear if this has been rigorously proved); the contribution alone of generalizing the melded CI to more than 2 parameters is interesting, as well as the applicability of their method to complex surveys where each individual has their own weight. There was clearly painstaking detail taken in simulation studies to evaluate the new method.}

    \item \textbf{The abstract and introduction imply that a main contribution of the work is that the new methods have better properties in simulations, and no drawbacks are hinted at. However, it is not clear that the new methods achieved better performance. Performance is strong at very low prevalences, but fades at higher prevalences. This is probably because the gamma CI method uses a Poisson approximation to the binomial that assumes a small binomial parameter, i.e., a small prevalence closer to 0 than 1.}

    \textbf{“our methods appear to guarantee coverage in simulated settings, while competing methods are shown to achieve much lower than nominal coverage” (Abstract).}

    \textbf{“we…show through simulations that [our new method] beats the best of [the established frequentist competitors] in each of the three stages **with respect to guaranteeing coverage**” (Introduction, last paragraph; emphasis added.) The three stages are (1) random samples with misclassification; (2) weighted samples without misclassification (using a perfect assay); and (3) weighted samples with misclassification.}


    We have added some mentions in the text about the drawbacks to our proposed methods and clarify the scenarios when our methods are shown to be superior:
    
    Abstract:
    ``We demonstrate that our methods appear to guarantee coverage in simulated settings, while competing methods are shown to achieve much lower than nominal coverage in some settings, especially when overall prevalence is very low. In other settings, our methods are shown to be overly conservative."
    
    Introduction:
    
    ``However, in some simulated settings, our proposed methods are overly conservative, while competitor methods maintain closer to nominal coverage."

    Discussion:
    ``These new confidence intervals appear to guarantee coverage in most simulated settings, including some scenarios where competitor methods dramatically under-cover.
    In general, our methods demonstrate higher coverage than competitor methods in most scenarios, sometimes being very conservative while competitor methods demonstrate closer to nominal coverage.""

    \item \textbf{The new method may guarantee coverage well, but it seems to do so by using conservative intervals that over-cover. Should such intervals be preferred to intervals that are more permissive (anti-conservative)?}
    
    \textcolor{red}{Mike, can you add any comments about this?}


    \item \textbf{For Stage 1 (Sections 2.2/3.1), consider Figure 1. The text states that “both [our new and the existing Lang-Reiczigel] methods achieve approximately nominal coverage, with the melding method being somewhat more conservative.” This definition of “approximately nominal” is debatable; the figure shows that the existing Lang-Reiczigel method achieves nominal 95\% coverage in most situations, while the melding method usually over-covers.}
    
    We have updated the text to more accurately reflect the simulation results:
    
    ``Figure~1 shows that, when specificity is less than perfect, the Lang-Reiczigel method achieves approximately nominal coverage, while the melding method is slightly more conservative, generally demonstrating 96\%-97\% coverage with 95\% confidence intervals."

    \item \textbf{(The discussion of lower and upper error probabilities in Section 3.1 is similar. The authors criticize the Lang-Reiczigel intervals for having “lower error above 2.5\%, which is undesirable…”. However, neither the lower nor upper errors of the melding method achieves nominal 2.5\% in any scenario. This is undesirable and unremarked upon. As a minor point, no reason for focusing on lower and upper error probabilities is stated; those Figures may be better relegated to the appendices.)}
    
    We have updated the text to motivate the figures and remark upon the undesirable lower error properties of the melding method:
    
    ``For a more nuanced depiction of each method's properties, we separate the overall coverage into lower and upper errors.
    Figure~3 shows that both methods make upper errors with roughly the same frequency.
    Figure~2 demonstrates that while the melding procedure bounds the lower error frequency below 2.5\%, the Lang-Reiczigel method generally has lower error above 2.5\%.
    Each of these behaviors may be undesirable, depending on the context in which the methods are applied.
    For applications in which there is a need to bound the lower errors, the melding method is superior."

    \item \textbf{For Stage 2 (Sections 2.3/3.2), Figures 4-5 display scenarios where prevalence is 0.5\%, and the new wsPoisson method generally performs well compared to competitors. However, the competitor methods demonstrate almost uniformly better properties (coverage closer to nominal) than the authors’ wsPoisson method when prevalence is 5\% in Figures 6-7. This is not pointed out in the textual description in the last paragraph of Section 3.2}

    We have updated the text to reflect this observation:
    ``In scenarios with higher overall prevalence, the Agresti-Coul and Korn-Graubard methods achieve close to nominal coverage, while the wsPoisson method strongly over-covers."

    \item \textbf{For Stage 3 (Sections 2.4/3.3), the only comparator shown in the Figures is the WprevSeSp Binomial developed in the Kalish et al. paper (despite the text saying wsPoisson was also compared). Again, the textual description belies the results in the Figures. While there are some scenarios in Figures 8-11 where the WprevSeSp Binomial interval under-covers dramatically, most scenarios appear to show that binomial interval having consistently closer-to-nominal coverage compared to the over-covering WprevSeSp Poisson.}
    
    In our simulations, we did compare the wsPoisson method to the two melding methods, but the results were poor and made comparison between the melding methods more difficult to observe in the figures.
    We have clarified this point in the text.
    We have also noted the generally superior performance of the WprevSeSp Binomial method:
    
    ``In the other scenarios tested, the WprevSeSp Binomial generally achieves closer to nominal coverage than the WprevSeSp Poisson."

    \item \textbf{Is there a substantive reason that the prevalences assessed in simulations are 0.5\% and 5\%? While the number of scenarios evaluated are clearly substantial, it would be interesting to understand the methods’ performance across a larger portion of the [0, 1] prevalence parameter space.}

    We only evaluated 0.5\% and 5\% because the greater prevalence leads to over-coverage for our methods.
    We have updated the text to point to this drawback throughout.

    \item If the main contribution of the paper is superior coverage properties, then the above issues of the Poisson approximation assuming a small prevalence as well as simulation results and interpretation should be addressed. The authors could instead elaborate on other contributions of the work detailed above.

    \item Minor issues:
    
    \begin{itemize}
        \item \textbf{2.2 Line 23-24: “where we define 0/0” seems unusual when this is typically taken as an indeterminate value. Clarify what is meant? The estimator in Equation 5 seems to be the Rogan-Gladen (1978) estimator with truncation in cases when the estimator falls outside the parameter range of [0, 1]?}
        
        We have adjusted the definition of the estimator to avoid defining 0/0 = 0. It is now presented as
        \begin{equation}
        \hat{\beta}^* \equiv 
        g(\hat{\theta}_1, \hat{\phi}_n, \hat{\phi}_p)
        \equiv 
        \left\{ 
        \begin{array}{ll}
        1 & \mbox{ if $\hat{\phi}_n < \hat{\phi}_p < \hat{\theta}_1$ }  \\
        \frac{\hat{\theta}_1 - \hat{\phi}_n}{\hat{\phi}_p - \hat{\phi}_n} & 
        \mbox{ if $\hat{\phi}_p > \hat{\theta}_1 \geq \hat{\phi}_n$ } \\
        0 & \mbox{ otherwise.} 
        \end{array}
        \right.
        \end{equation}

        \item \textbf{2.2 Lines 24-32: It would be helpful for the unfamiliar reader to include more background on the melding method. For instance, what exactly is the definition of the confidence distribution? Why are the confidence distributions Beta for a binomial experiment?}
        
        I have added the definition of the confidence distribution to section 2.2
        \textcolor{red}{Mike, feel free to add more context/intution.}

        \item \textbf{As a formatting note, the paper could be much more concise if (a) many of the figures were moved to appendices, and (b) fewer lines are used for equations, e.g., the definition of the Lang-Reiczigel interval in Section 2.2.}
        
        We have adjusted the presentation of Section 2.2 to reduce the lines used.

        \item \textbf{Please elaborate on why the third equality in Section 2.5.2, p. 8, lines 17-25 (variance of  beta-hat) holds.}

        The referenced equation is reproduced here:
        \begin{eqnarray*}
        \textrm{var}_P \left(\hat{\beta} \right) & = & \textrm{var}_P \left(  \frac{1}{n}  \sum_{i=1}^{n} \sum_{j=1}^{N}  \frac{ I_{ij}  Y_j}{N P_j} \right)  \\
        & = &    \sum_{i=1}^{n} \sum_{j=1}^{N}  \frac{ \textrm{var}_P( I_{ij})  Y_j^2}{n^2 N^2 P_j^2}  \\
        & = &    \sum_{i=1}^{n} \sum_{j=1}^{N}  \frac{   Y_j}{n^2 N^2 P_j}.
        \end{eqnarray*}
        
        The third equality holds because \( \textrm{var}_P( I_{ij}) = P_j \) and \( Y_j^2= Y_j \), because \( Y_j \) is binary.
        
        We have clarified this in the text:
        
        \begin{eqnarray*}
        \textrm{var}_P \left(\hat{\beta} \right) & = & \textrm{var}_P \left(  \frac{1}{n}  \sum_{i=1}^{n} \sum_{j=1}^{N}  \frac{ I_{ij}  Y_j}{N P_j} \right)  \\
        & = &    \sum_{i=1}^{n} \sum_{j=1}^{N}  \frac{ \textrm{var}_P( I_{ij})  Y_j^2}{n^2 N^2 P_j^2}  \\
        & = &    \sum_{i=1}^{n} \sum_{j=1}^{N}  \frac{ \textrm{var}_P( I_{ij})  Y_j}{n^2 N^2 P_j^2}  \\
        & = &    \sum_{i=1}^{n} \sum_{j=1}^{N}  \frac{   Y_j}{n^2 N^2 P_j}.
        \end{eqnarray*}
        

        \item \textbf{There are several typographical errors that distract the reader. The manuscript should be reread with this attention to detail in mind. Some instances: 2.3 Line 52: “the wsPoison method”; Section 5: “Further worked is needed”; the inconsistency about the assessment of wsPoisson in the simulations; etc.}
        
        \textcolor{red}{Damon: I fixed these errors and a few more. Mike and Barry should also take a look for proofreading.}

    \end{itemize}
\end{itemize}

\end{document}
